{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROm8kovwJIxD"
      },
      "source": [
        "# GANs with Hands\n",
        "\n",
        "In this project, we will build a Generative Adversarial Network (GAN) that generates pictures of hands. These will be trained on a dataset of hand images doing sign language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0OwpFl8JIxP"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3nvoSP3Btzu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yxy_M7xbQef-"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cg_4z8-glz6P"
      },
      "outputs": [],
      "source": [
        "def plot_results(images, n_cols=None):\n",
        "    '''visualizes fake images'''\n",
        "    display.clear_output(wait=False)\n",
        "\n",
        "    n_cols = n_cols or len(images)\n",
        "    n_rows = (len(images) - 1) // n_cols + 1\n",
        "\n",
        "    if images.shape[-1] == 1:\n",
        "        images = np.squeeze(images, axis=-1)\n",
        "\n",
        "    plt.figure(figsize=(n_cols, n_rows))\n",
        "\n",
        "    for index, image in enumerate(images):\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(image, cmap=\"binary\")\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iI8bUNSJIxR"
      },
      "source": [
        "## Get the training data\n",
        "\n",
        "We will download the dataset and extract it to a directory in our workspace. As mentioned, these are images of human hands performing sign language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIx-60V_BEyo"
      },
      "outputs": [],
      "source": [
        "# download the dataset\n",
        "training_url = \"https://storage.googleapis.com/tensorflow-1-public/tensorflow-3-temp/signs-training.zip\"\n",
        "training_file_name = \"signs-training.zip\"\n",
        "urllib.request.urlretrieve(training_url, training_file_name)\n",
        "\n",
        "# extract to local directory\n",
        "training_dir = \"/tmp\"\n",
        "zip_ref = zipfile.ZipFile(training_file_name, 'r')\n",
        "zip_ref.extractall(training_dir)\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iPZmV9RJIxR"
      },
      "source": [
        "## Preprocess the images\n",
        "\n",
        "Next, we will prepare the dataset to a format suitable for the model. We will read the files, convert it to a tensor of floats, then normalize the pixel values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rf-e4f-d3H7"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "# mapping function for preprocessing the image files\n",
        "def map_images(file):\n",
        "  '''converts the images to floats and normalizes the pixel values'''\n",
        "  img = tf.io.decode_png(tf.io.read_file(file))\n",
        "  img = tf.dtypes.cast(img, tf.float32)\n",
        "  img = img / 255.0\n",
        "\n",
        "  return img\n",
        "\n",
        "# create training batches\n",
        "filename_dataset = tf.data.Dataset.list_files(\"/tmp/signs-training/*.png\")\n",
        "image_dataset = filename_dataset.map(map_images).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz9NfgdTJIxS"
      },
      "source": [
        "## Build the generator\n",
        "\n",
        "- *Dense*: number of units should equal `7 * 7 * 128`, input_shape takes in a list containing the random normal dimensions.\n",
        "    - `random_normal_dimensions` is a hyperparameter that defines how many random numbers in a vector you'll want to feed into the generator as a starting point for generating images.\n",
        "- *Reshape*: reshape the vector to a 7 x 7 x 128 tensor.\n",
        "- *BatchNormalization*\n",
        "- *Conv2DTranspose*: takes `64` units, kernel size is `5`, strides is `2`, padding is `SAME`, activation is `selu`.\n",
        "- *BatchNormalization*\n",
        "- *Conv2DTranspose*: `1` unit, kernel size is `5`, strides is `2`, padding is `SAME`, and activation is `tanh`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uagZDaF0CZON"
      },
      "outputs": [],
      "source": [
        "# Build the generator\n",
        "random_normal_dimensions = 32\n",
        "\n",
        "generator = keras.models.Sequential([\n",
        "    keras.layers.Dense(7 * 7 * 128, input_shape=[random_normal_dimensions]),\n",
        "    keras.layers.Reshape([7, 7, 128]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"SAME\", activation=\"selu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2DTranspose(1, kernel_size=5, strides=2, padding=\"SAME\", activation=\"tanh\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_lAy0bjJIxS"
      },
      "source": [
        "## Build the discriminator\n",
        "\n",
        "Here is the recommended architecture for the discriminator:\n",
        "- *Conv2D*: 64 units, kernel size of 5, strides of 2, padding is SAME, activation is a leaky relu with alpha of 0.2, input shape is 28 x 28 x 1\n",
        "- *Dropout*: rate is 0.4 (fraction of input units to drop)\n",
        "- *Conv2D*: 128 units, kernel size of 5, strides of 2, padding is SAME, activation is LeakyRelu with alpha of 0.2\n",
        "- *Dropout*: rate is 0.4.\n",
        "- *Flatten*\n",
        "- *Dense*: with 1 unit and a sigmoid activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siCh-qRtJIxT",
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "# Build the discriminator\n",
        "\n",
        "discriminator = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(64, kernel_size=5, strides=2, padding=\"SAME\",\n",
        "                        activation=keras.layers.LeakyReLU(0.2),\n",
        "                        input_shape=[28, 28, 1]),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Conv2D(128, kernel_size=5, strides=2, padding=\"SAME\",\n",
        "                        activation=keras.layers.LeakyReLU(0.2)),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKlTL1lhJIxT"
      },
      "source": [
        "## Compile the discriminator\n",
        "\n",
        "- Compile the discriminator with a binary_crossentropy loss and rmsprop optimizer.\n",
        "- Set the discriminator to not train on its weights (set its \"trainable\" field)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xh4EaHDlJIxT"
      },
      "outputs": [],
      "source": [
        "# Compile the discriminator\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "discriminator.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3X25T2kUJIxT"
      },
      "source": [
        "## Build and compile the GAN model\n",
        "\n",
        "- Build the sequential model for the GAN, passing a list containing the generator and discriminator.\n",
        "- Compile the model with a binary cross entropy loss and rmsprop optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBclsOMsJIxU"
      },
      "outputs": [],
      "source": [
        "# Build and compile the GAN model\n",
        "\n",
        "gan = keras.models.Sequential([generator, discriminator])\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX2CB0srJIxU"
      },
      "source": [
        "## Train the GAN\n",
        "\n",
        "Phase 1\n",
        "- real_batch_size: Get the batch size of the input batch (it's the zero-th dimension of the tensor)\n",
        "- noise: Generate the noise using `tf.random.normal`.  The shape is batch size x random_normal_dimension\n",
        "- fake images: Use the generator that you just created. Pass in the noise and produce fake images.\n",
        "- mixed_images: concatenate the fake images with the real images.\n",
        "  - Set the axis to 0.\n",
        "- discriminator_labels: Set to `0.` for fake images and `1.` for real images.\n",
        "- Set the discriminator as trainable.\n",
        "- Use the discriminator's `train_on_batch()` method to train on the mixed images and the discriminator labels.\n",
        "\n",
        "\n",
        "Phase 2\n",
        "- noise: generate random normal values with dimensions batch_size x random_normal_dimensions\n",
        "  - Use `real_batch_size`.\n",
        "- Generator_labels: Set to `1.` to mark the fake images as real\n",
        "  - The generator will generate fake images that are labeled as real images and attempt to fool the discriminator.\n",
        "- Set the discriminator to NOT be trainable.\n",
        "- Train the GAN on the noise and the generator labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuV97d_kCpb_"
      },
      "outputs": [],
      "source": [
        "# Train the GAN - complete training loop\n",
        "def train_gan(gan, dataset, random_normal_dimensions, n_epochs=50):\n",
        "    generator, discriminator = gan.layers\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))\n",
        "        for real_images in dataset:\n",
        "\n",
        "            # infer batch size from the current batch of real images\n",
        "            real_batch_size = real_images.shape[0]\n",
        "\n",
        "            # Train the discriminator - PHASE 1\n",
        "            noise = tf.random.normal([real_batch_size, random_normal_dimensions])\n",
        "\n",
        "            # Use the noise to generate fake images\n",
        "            fake_images = generator(noise)\n",
        "\n",
        "            # Create a list by concatenating the fake images with the real ones\n",
        "            mixed_images = tf.concat([fake_images, real_images], axis=0)\n",
        "\n",
        "            # Create the labels for the discriminator: 0 for fake, 1 for real\n",
        "            discriminator_labels = tf.constant([[0.]] * real_batch_size + [[1.]] * real_batch_size)\n",
        "\n",
        "            # Ensure that the discriminator is trainable\n",
        "            discriminator.trainable = True\n",
        "\n",
        "            # Train discriminator on mixed images\n",
        "            discriminator.train_on_batch(mixed_images, discriminator_labels)\n",
        "\n",
        "            # Train the generator - PHASE 2\n",
        "            noise = tf.random.normal([real_batch_size, random_normal_dimensions])\n",
        "\n",
        "            # Label all generated images as real (1.)\n",
        "            generator_labels = tf.constant([[1.]] * real_batch_size)\n",
        "\n",
        "            # Freeze the discriminator\n",
        "            discriminator.trainable = False\n",
        "\n",
        "            # Train the GAN (which trains the generator)\n",
        "            gan.train_on_batch(noise, generator_labels)\n",
        "\n",
        "        plot_results(fake_images, 16)\n",
        "        plt.show()\n",
        "    return fake_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzbX3hwKJIxW"
      },
      "source": [
        "### Run the training\n",
        "\n",
        "For each epoch, a set of 31 images will be displayed onscreen. The longer we train, the better our output fake images will be. We will pick your best images to submit to the grader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYx9rzdACt0A"
      },
      "outputs": [],
      "source": [
        "# you can adjust the number of epochs\n",
        "EPOCHS = 60\n",
        "\n",
        "# run the training loop and collect images\n",
        "fake_images = train_gan(gan, image_dataset, random_normal_dimensions, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 1 – RECOMMENDED: Native Keras format (new standard)\n",
        "generator.save(\"sign_language_gan_generator.keras\")     # <-- .keras extension\n",
        "\n",
        "# Option 2 – Classic HDF5 format (still works everywhere)\n",
        "# generator.save(\"sign_language_gan_generator.h5\")\n",
        "\n",
        "# Optional: save the full GAN if you want to resume training later\n",
        "gan.save(\"sign_language_gan_full.keras\")"
      ],
      "metadata": {
        "id": "2Uv7ck4-13kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the generator\n",
        "generator = tf.keras.models.load_model(\"sign_language_gan_generator.keras\")\n",
        "# or if you used h5:\n",
        "# generator = tf.keras.models.load_model(\"sign_language_gan_generator.h5\")\n",
        "\n",
        "print(\"Generator loaded successfully!\")"
      ],
      "metadata": {
        "id": "YUOqBCyn13a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_hands(n=16, seed=None):\n",
        "    if seed is not None:\n",
        "        tf.random.set_seed(seed)\n",
        "    noise = tf.random.normal([n, 32])  # 32 = random_normal_dimensions\n",
        "    imgs = generator(noise, training=False)\n",
        "    imgs = (imgs + 1) * 127.5           # tanh output → [0, 255]\n",
        "    imgs = tf.cast(imgs, tf.uint8)\n",
        "    return imgs\n",
        "\n",
        "# Example\n",
        "hands = generate_hands(25, seed=123)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.imshow(hands[i,:,:,0], cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6YNc8gF52Gxb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}